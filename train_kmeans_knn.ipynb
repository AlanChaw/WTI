{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from feature_extract_inference import FeatureExtract\n",
    "\n",
    "class KmeansKnnModel:\n",
    "    def __init__(self,\\\n",
    "                 model_version = \"v2_best\",\n",
    "                 num_of_clusters = 30,\n",
    "                 num_of_k_neibors = 20,\n",
    "                 train_data_path = \"data/v1/train_set_v1.txt\",\n",
    "                 dev_data_path = \"data/v1/dev_set_v1.txt\"\n",
    "                ):\n",
    "        self.model_version = model_version\n",
    "        self.num_of_clusters = num_of_clusters\n",
    "        self.num_of_k_neibors = num_of_k_neibors\n",
    "        self.kmeans_model_path = \\\n",
    "                \"checkpoints/kmeans_model_{0}_clusters_{1}.m\".format(\\\n",
    "                    self.model_version,\\\n",
    "                    self.num_of_clusters)\n",
    "        self.knn_model_path = \\\n",
    "                \"checkpoints/knn_model_{0}\".format(self.model_version)\n",
    "        self.train_data_path = train_data_path\n",
    "        self.dev_data_path = dev_data_path\n",
    "        \n",
    "    def trainKmeansClf(self, train_data):\n",
    "        kmeans_clf = KMeans(n_clusters=self.num_of_clusters).fit(train_data)\n",
    "        joblib.dump(kmeans_clf, self.kmeans_model_path)\n",
    "        return kmeans_clf\n",
    "\n",
    "    def getKmeansClfModel(self):\n",
    "        return joblib.load(self.kmeans_model_path)\n",
    "\n",
    "    def trainKnnClf(self, clf_number, X, y):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=self.num_of_k_neibors)\n",
    "        knn_clf.fit(X, y)\n",
    "        clf_path = \"{0}_cluster_{1}.m\".format(self.knn_model_path, clf_number)\n",
    "        joblib.dump(knn_clf, clf_path)\n",
    "        return knn_clf\n",
    "\n",
    "    def getKnnClfModel(self, clf_number):\n",
    "        clf_path = \"{0}_cluster_{1}.m\".format(self.knn_model_path, clf_number)\n",
    "        return joblib.load(clf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64):\n",
    "    m = len(X)\n",
    "    mini_batches = []\n",
    "\n",
    "    num_complete_minibatches = int(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = X[k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = Y[k * mini_batch_size : (k + 1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = X[num_complete_minibatches * mini_batch_size:]\n",
    "        mini_batch_Y = Y[num_complete_minibatches * mini_batch_size:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(data_path, mini_batch_size=1):\n",
    "    label_list = []\n",
    "    sentence_list = []\n",
    "    with open(data_path) as data_file:\n",
    "        for line in data_file.readlines():\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            label_list.append(line[0])\n",
    "            sentence_list.append(line[1])\n",
    "\n",
    "    if 1 == mini_batch_size:\n",
    "        label_list = np.array(label_list)\n",
    "        return sentence_list, label_list\n",
    "    else:\n",
    "        mini_batches = random_mini_batches(sentence_list, label_list, mini_batch_size)\n",
    "        return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_knn_learner = KmeansKnnModel()\n",
    "sentence_list, label_list = readData(kmeans_knn_learner.train_data_path)\n",
    "dev_sentence, dev_label = readData(kmeans_knn_learner.dev_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureList(sentence_list, use_batch=False):\n",
    "    test_model = FeatureExtract()\n",
    "    if use_batch:\n",
    "        first_sencence_list = sentence_list[0][0]\n",
    "        feature_list = test_model.get_features(first_sencence_list)\n",
    "        for batch in sentence_list[1:]:\n",
    "            feature = test_model.get_features(list(batch[0]))\n",
    "            feature_list = np.concatenate((feature_list, feature))\n",
    "    else:\n",
    "        feature_list = []\n",
    "        for sentence in sentence_list:\n",
    "            feature = test_model.get_features([sentence])\n",
    "            feature_list.append(np.ravel(feature))\n",
    "        feature_list = np.array(feature_list)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52min 33s, sys: 4min 59s, total: 57min 32s\n",
      "Wall time: 10min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training and Dev set feature list\n",
    "mini_batches  = readData(kmeans_knn_learner.train_data_path, 64)\n",
    "feature_list = getFeatureList(mini_batches, True)\n",
    "dev_mini_batches  = readData(kmeans_knn_learner.dev_data_path, 64)\n",
    "dev_feature_list = getFeatureList(dev_mini_batches, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "num_of_clusters: 3\n",
      "num_of_k_neibors: 1\n",
      "Dev set precision: 9/36116=0.000\n",
      "-----------------------------------------------------------\n",
      "num_of_clusters: 3\n",
      "num_of_k_neibors: 5\n",
      "Dev set precision: 5/36116=0.000\n",
      "-----------------------------------------------------------\n",
      "num_of_clusters: 3\n",
      "num_of_k_neibors: 10\n",
      "Dev set precision: 3/36116=0.000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 192)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sml/lib/python3.7/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sml/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    548\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 550\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 192)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# KMeans training\n",
    "clusters_list = [3,5,10]\n",
    "neibors_list = [1,5,10]\n",
    "for num_of_clusters in clusters_list:\n",
    "    kmeans_knn_learner.num_of_clusters = num_of_clusters\n",
    "    kmeans_clf = kmeans_knn_learner.trainKmeansClf(feature_list)\n",
    "    for num_of_k_neibors in neibors_list:\n",
    "        kmeans_knn_learner.num_of_k_neibors = num_of_k_neibors\n",
    "        # KNN training\n",
    "        for i in np.unique(kmeans_clf.labels_):\n",
    "            cluster_index = (kmeans_clf.labels_ == i)\n",
    "            knn_clf = kmeans_knn_learner.trainKnnClf(i, feature_list[cluster_index], label_list[cluster_index])\n",
    "        \n",
    "        # Predicting\n",
    "        kmeans_predicted_list = kmeans_clf.predict(dev_feature_list)\n",
    "        correct = 0\n",
    "        for label in np.unique(kmeans_clf.labels_):\n",
    "            index_list = (kmeans_predicted_list==label)\n",
    "            temp_feature_list = dev_feature_list[index_list]\n",
    "            temp_label_list = dev_label[index_list]\n",
    "            knn_clf = kmeans_knn_learner.getKnnClfModel(label)\n",
    "            knn_predicted_list = knn_clf.predict(temp_feature_list)\n",
    "            temp_correct = sum(temp_label_list==knn_predicted_list)\n",
    "            temp_len = len(temp_label_list)\n",
    "            correct += temp_correct\n",
    "            temp_precision = temp_correct / temp_len\n",
    "            #print(\"------------------------------------------------------\")\n",
    "            #print(\"KNN classifier {0} precision: {1}/{2}={3:.3f}\".format(label, temp_correct, temp_len, temp_precision))\n",
    "        precision = correct / len(dev_label)\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(\"num_of_clusters: {0}\".format(num_of_clusters))\n",
    "        print(\"num_of_k_neibors: {0}\".format(num_of_k_neibors))\n",
    "        print(\"Dev set precision: {0}/{1}={2:.3f}\".format(correct ,len(dev_label), precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
