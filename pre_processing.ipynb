{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = [\"@handle\", \"rt\", \"http\"]\n",
    "\n",
    "def pre_process(sentence):\n",
    "    sentence = sentence.split()\n",
    "    target_remove = set()\n",
    "    for token in sentence:\n",
    "        for target in remove_words:\n",
    "            if target in token:\n",
    "                target_remove.add(token)\n",
    "                \n",
    "    for target in target_remove:\n",
    "        sentence.remove(target)\n",
    "    \n",
    "    sentence = ' '.join(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train data to train_dict. \n",
    "train_dict[id] = [[train_instace1], [train_instance2] ....]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 328194\n",
      "Total ids: 9292\n",
      "Empty sentence counter: 998\n",
      "Time spent: 2074.16ms\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import collections\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "time_start=time.time()\n",
    "\n",
    "train_file_path = \"data/train_tweets.txt\"\n",
    "train_dict = collections.defaultdict(list)\n",
    "\n",
    "empty_sentence_counter = 0\n",
    "with open(train_file_path, encoding='utf-8') as tsvfile:\n",
    "    reader = csv.reader((x.replace('\\0', '') for x in tsvfile), delimiter='\\t')\n",
    "    for i, row in enumerate(reader):\n",
    "        id = int(row[0])\n",
    "        instance = pre_process(row[1].lower())\n",
    "        if not instance == \"\":\n",
    "            train_dict[id].append(instance)\n",
    "        else:\n",
    "            #print(\"Empty sentence row:{0}\".format(i+1))\n",
    "            #print(\"id: {0}\".format(id))\n",
    "            #print(\"sentenc: {0}\".format(instance))\n",
    "            empty_sentence_counter += 1\n",
    "    print(\"Total rows: %d\" % i)\n",
    "print(\"Total ids: %d\" % len(train_dict))\n",
    "\n",
    "time_end=time.time()\n",
    "print(\"Empty sentence counter: {0}\".format(empty_sentence_counter))\n",
    "print(\"Time spent: {0:.2f}ms\".format((time_end-time_start)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i'm looking for a recommendation for a leasing call center other than level one. any suggestions?\", \"i'm at triple rock brewing in berkeley...great spot to watch the yankees win!\", 'whostalkin.com is a great source as well #aptchat', 'i also use google on all our comps #aptchat', 'hi! matt here from recp. i also use google usually receive craigslist ads or ratings from the #aptchat', 'shopping on oakland today....so far i like what i see', 'rt real-time social media stats from @handle', 'does your social class determine your online social network? - #cnn', 'the new paramount theatre sign is up! they are going to light it on 10/21/09 at 6:00 pm!! you should all come!', 'cl now asking for phone numbers to verify your posting.looks like it is localized to socal so far. anyone else seeing this?', 'i humbly remind u that bad reviews r not the problem, but a symptom', \"udr's augmented reality search application passes 25,000 downloads\", 'off to dempression...any tubers in the house?', 'it buying a tv to see it?', 'social media facts - did you know 4.0', \"oday's blue angels show cancelled due to heavy fog:\", 'timing is everything...happy to be a instead of reading transcripts', 'communities have the advantage over every other business because we already have a physical comm. to leverage sm tools #reachat', 'sm tools are great for spreading information through your peer network. pictures/videos illustrate what you are selling #reachat', 'looking forward to #reachat with and @handle and @handle', \"the poke at yabbi's is amazing.....props to the waiter for hooking us up\", \"here's one list of twitter chat's any others?\", \"aptchat today at 4 pm et - more attention on retention! w/ & @handle from satisfacts. don't miss it! #aptchat\", \"hey peeps...new blog post - transparency - don't leave your residents in the dark -\", \"camden's ric campo credits at least 37 leases directly from twitter. rentwiki integrates w/twitter #nmhc via\", 'petshop boys at the warfield', 'alta phoenix lofts #1 phoenix!!!!! congrats to all involved', 'great last night...met some talented people', 'a small business guide to text-message marketing -', 'please add me to the #awsms09 thanks', 'great bike ride to gg bridge ...now headed to watch il trovatore at at&t park.', 'community events are the key ingredient to resident retention', 'you should get a fan page so all your fans can cheer you on', 'tomorrow: \"is print really as dead as some people say?\" bring a friend & your best ideas - 4 pm et. #aptchat', 'new blog posting', \"check out our newest post 'building community relationships through activities'\", 'you need an iphone optimized website', 'social media', 'great tips for creating facebook fan', 'free web seminar for managers: 5 steps to maximize your online marketing', 'to bad online customer reviews #aptchat', 'an veteran shares some lab experiments in social media marketing | viralhousingfix', 'stay on top of your social media game', 'from burning man to denver to sf...time to wash off the playa dust', 'community events are the key ingredient to resident retention', 'great bike ride to gg bridge ...now headed to watch il trovatore at at&t park.', 'launched the new socially connected settlers creek', 'please add me to the #awsms09 thanks', 'great last night...met some talented people', 'alta phoenix lofts #1 phoenix!!!!! congrats to all involved']\n"
     ]
    }
   ],
   "source": [
    "print(train_dict[1319])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dev Train\n",
    "!! There are Some ID have 0 train instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9292 9292 9292\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "dev_split = 0.1\n",
    "train_split = 1 - dev_split\n",
    "\n",
    "dev_set_dict = {}\n",
    "train_set_dict = {}\n",
    "\n",
    "for id in train_dict:\n",
    "    target_list = train_dict[id]\n",
    "    length = len(target_list)\n",
    "    random.shuffle(target_list)\n",
    "    split = int(np.ceil(length*dev_split))\n",
    "    dev_set_dict[id] = target_list[:split]\n",
    "    train_set_dict[id] = target_list[split:length]\n",
    "#     print(len(dev_set_dict[id]), len(train_set_dict[id]), length)\n",
    "\n",
    "print(len(dev_set_dict), len(train_set_dict), len(train_dict))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(target_dict, file_path):\n",
    "    file_lines = []\n",
    "    for id in target_dict:\n",
    "        for sentence in target_dict[id]:\n",
    "            file_lines.append(str(id) + '\\t' + sentence + '\\n')\n",
    "            \n",
    "    random.shuffle(file_lines)\n",
    "    with open(file_path, 'w+') as file:\n",
    "        for item in file_lines:\n",
    "            file.write(item)\n",
    "    return\n",
    "\n",
    "dev_set_path = 'data/v1/dev_set_v1.txt'\n",
    "train_set_path = 'data/v1/train_set_v1.txt'\n",
    "\n",
    "save_to_file(dev_set_dict, dev_set_path)\n",
    "save_to_file(train_set_dict, train_set_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
